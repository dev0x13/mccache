#pragma once

#include <cassert>
#include <string>
#include <vector>

#include "matrix.h"
#include "stats_accumulators.h"
#include "vector.h"

class EvolvingMarkovChain {
 public:
  // statsAccumulatorType - type of stats accumulator ("states" | "transitions")
  // accessesThreshold - number of state accesses required to generate
  // predictions using transitions matrix (if actual number is below the
  // threshold, then stats accumulator is used for prediction).
  EvolvingMarkovChain(const std::string& statsAccumulatorType,
                      size_t accessesThreshold);

  // Registers new state, returns its number.
  size_t AddState();

  // Registers new transitions from state1 to state2.
  void RegisterTransition(size_t state1, size_t state2);

  // Gives a prediction on the next state if current state == currentStateNum.
  // nextState output vector should be pre-allocated to be numStates size.
  // This type of prediction is cheap: no matrix-vector multiplications are
  // performed. Predictions generated by this method contain non-normalized
  // values (i.e. there are no limits for them). If you want to transform them
  // to probabilities just divide the vector by its elements sum.
  void PredictNextState(size_t currentStateNum, Vector<float>* nextState);

  // Gives a prediction on the next state using given current state vector.
  // This is expensive type of prediction, but it can be used for long (>1)
  // forecasts. Predictions generated by this method are guaranteed to contain
  // normalized probability values and their sum equals to 1.
  Vector<float> PredictNextState(const Vector<float>& currentState);

  // Returns a single non-normalized probability of transition from state1 to
  // state2 based on accumulated statistics and not on transition matrix.
  // Intended to be used to fix predicted state if it contains freshly added
  // state, transition probability to which is apparently equals to zero. In
  // such case this method is used to retrieve some kind of an a priori
  // probability.
  float GetTransitionProbabilityFromAccumulator(size_t state1,
                                                size_t state2) const;

  // Returns the stochastic matrix.
  const Matrix<float>& GetStochasticMatrix();

  const size_t& GetNumStates() const;

  void PrintTransitionsStatsMatrix() const;

  ~EvolvingMarkovChain();

 private:
  void UpdateStochasticMatrix();

  size_t num_states_ = 0;
  size_t accesses_threshold_ = 0;

  // Contains a right stochastic matrix for transitions.
  // This matrix is updated lazily as its update require a lot of memory copying
  // and computations. It is used only for prediction with forecast length > 1.
  // If need_to_update_stochastic_matrix_ == false then it is guaranteed that
  // this matrix is updated regarding the transition_stats_matrix_ and each row
  // in it contains the true probabilities which sums to 1.
  Matrix<float> stochastic_matrix_;
  bool need_to_update_stochastic_matrix_ = true;

  // Contains the accumulated (i.e. actually observed) number of transitions
  // between states. It is more efficient to store this matrix as STL vectors,
  // because of its "smart" resizing and no need to copy all the elements on
  // each resize (copy is apparently needed, when matrix is stored as a single
  // pointer with a row-major order).
  std::vector<std::vector<float>> transition_stats_matrix_;

  // Contains the sum of elements for each transitionsStatsMatrix row.
  std::vector<float> states_access_counters_;

  // Transitions statistics accumulator. It is used for next state prediction in
  // case if the statistics of transitions from the exact given state is
  // insufficient: most likely we don't want to get the maximum probability of
  // state1 -> state2 transition if we observed it for a one time or in case if
  // we haven't observed any of "from state1" transitions yet, but we are at
  // state1 now and want to predict the next one. Thus, we need this hacky stats
  // accumulator to deal with growing state space of the stochastic process,
  // which is being modeled with this markov-chain-like model.
  StatsAccumulator* stats_accumulator_{nullptr};
};
